apiVersion: apps/v1
kind: Deployment
metadata:
  name: qwen
  labels:
    {{- include "rag-demo.labels" . | nindent 4 }}
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: qwen
  template:
    metadata:
      labels:
        app: qwen
    spec:
      containers:
        - name: qwen
          image: vllm/vllm-openai:latest   # <- Keep GPU image
          command: [ "python3", "-m", "vllm.entrypoints.openai.api_server" ]
          args:
            - "--model"
            - "$(MODEL_NAME)"
            - "--dtype"
            - "auto"
            - "--gpu-memory-utilization"
            - "$(GPU_MEMORY_UTILIZATION)"
            - "--max-model-len"
            - "$(MAX_MODEL_LEN)"
            - "--max-num-seqs"
            - "4"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          env:
            - name: MODEL_NAME
              value: {{ .Values.qwen.model | quote }}
            - name: GPU_MEMORY_UTILIZATION
              value: {{ .Values.qwen.gpuMemoryUtilization | default 0.75 | quote }}
            - name: MAX_MODEL_LEN
              value: {{ .Values.qwen.maxModelLen | default 11712 | quote }}
            - name: VLLM_LOGGING_LEVEL
              value: DEBUG
          resources:
            limits:
              nvidia.com/gpu: "1"
          ports:
            - containerPort: 8000
              name: http
